{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "Select only the features from above.\n",
    "Check if the missing values are presented in the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age           job  marital  education default  balance housing loan  \\\n",
      "0   58    management  married   tertiary      no     2143     yes   no   \n",
      "1   44    technician   single  secondary      no       29     yes   no   \n",
      "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
      "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
      "4   33       unknown   single    unknown      no        1      no   no   \n",
      "\n",
      "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
      "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
      "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
      "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
      "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
      "4  unknown    5   may       198         1     -1         0  unknown  no  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the full path to the CSV file\n",
    "csv_path = r'C:\\Users\\marti\\Desktop\\Machine_Learning\\Zoomcamp\\bank-full.csv'\n",
    "\n",
    "# Load the data from the CSV file\n",
    "df = pd.read_csv(csv_path, sep=';')\n",
    "\n",
    "# Check the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select specific columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age           job  marital  education  balance housing  contact  day month  \\\n",
      "0   58    management  married   tertiary     2143     yes  unknown    5   may   \n",
      "1   44    technician   single  secondary       29     yes  unknown    5   may   \n",
      "2   33  entrepreneur  married  secondary        2     yes  unknown    5   may   \n",
      "3   47   blue-collar  married    unknown     1506     yes  unknown    5   may   \n",
      "4   33       unknown   single    unknown        1      no  unknown    5   may   \n",
      "\n",
      "   duration  campaign  pdays  previous poutcome   y  \n",
      "0       261         1     -1         0  unknown  no  \n",
      "1       151         1     -1         0  unknown  no  \n",
      "2        76         1     -1         0  unknown  no  \n",
      "3        92         1     -1         0  unknown  no  \n",
      "4       198         1     -1         0  unknown  no  \n"
     ]
    }
   ],
   "source": [
    "# Select only the specified columns\n",
    "columns = ['age', 'job', 'marital', 'education', 'balance', 'housing', 'contact', \n",
    "           'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'y']\n",
    "df = df[columns]\n",
    "\n",
    "# Display the first few rows of the selected columns\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " age          0\n",
      "job          0\n",
      "marital      0\n",
      "education    0\n",
      "balance      0\n",
      "housing      0\n",
      "contact      0\n",
      "day          0\n",
      "month        0\n",
      "duration     0\n",
      "campaign     0\n",
      "pdays        0\n",
      "previous     0\n",
      "poutcome     0\n",
      "y            0\n",
      "dtype: int64\n",
      "\n",
      "Columns with missing values:\n",
      " Series([], dtype: bool)\n",
      "\n",
      "DataFrame info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 15 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        45211 non-null  int64 \n",
      " 1   job        45211 non-null  object\n",
      " 2   marital    45211 non-null  object\n",
      " 3   education  45211 non-null  object\n",
      " 4   balance    45211 non-null  int64 \n",
      " 5   housing    45211 non-null  object\n",
      " 6   contact    45211 non-null  object\n",
      " 7   day        45211 non-null  int64 \n",
      " 8   month      45211 non-null  object\n",
      " 9   duration   45211 non-null  int64 \n",
      " 10  campaign   45211 non-null  int64 \n",
      " 11  pdays      45211 non-null  int64 \n",
      " 12  previous   45211 non-null  int64 \n",
      " 13  poutcome   45211 non-null  object\n",
      " 14  y          45211 non-null  object\n",
      "dtypes: int64(7), object(8)\n",
      "memory usage: 5.2+ MB\n",
      "\n",
      "Statistical summary:\n",
      "                 age        balance           day      duration      campaign  \\\n",
      "count  45211.000000   45211.000000  45211.000000  45211.000000  45211.000000   \n",
      "mean      40.936210    1362.272058     15.806419    258.163080      2.763841   \n",
      "std       10.618762    3044.765829      8.322476    257.527812      3.098021   \n",
      "min       18.000000   -8019.000000      1.000000      0.000000      1.000000   \n",
      "25%       33.000000      72.000000      8.000000    103.000000      1.000000   \n",
      "50%       39.000000     448.000000     16.000000    180.000000      2.000000   \n",
      "75%       48.000000    1428.000000     21.000000    319.000000      3.000000   \n",
      "max       95.000000  102127.000000     31.000000   4918.000000     63.000000   \n",
      "\n",
      "              pdays      previous  \n",
      "count  45211.000000  45211.000000  \n",
      "mean      40.197828      0.580323  \n",
      "std      100.128746      2.303441  \n",
      "min       -1.000000      0.000000  \n",
      "25%       -1.000000      0.000000  \n",
      "50%       -1.000000      0.000000  \n",
      "75%       -1.000000      0.000000  \n",
      "max      871.000000    275.000000  \n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each column\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values per column:\\n\", missing_values)\n",
    "\n",
    "# Check which columns have any missing values\n",
    "missing_columns = df.isnull().any()\n",
    "print(\"\\nColumns with missing values:\\n\", missing_columns[missing_columns == True])\n",
    "\n",
    "# Get a summary of the DataFrame\n",
    "print(\"\\nDataFrame info:\\n\")\n",
    "df.info()\n",
    "\n",
    "# Get a statistical summary of the DataFrame\n",
    "print(\"\\nStatistical summary:\\n\", df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "What is the most frequent observation (mode) for the column education?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode of the 'education' column: secondary\n"
     ]
    }
   ],
   "source": [
    "# Mode of the 'education' column\n",
    "mode_education = df['education'].mode()[0]\n",
    "print(\"Mode of the 'education' column:\", mode_education)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Create the correlation matrix for the numerical features of your dataset. In a correlation matrix, you compute the correlation coefficient between every pair of features.\n",
    "\n",
    "What are the two features that have the biggest correlation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous  pdays    0.45482\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Select the numerical columns\n",
    "numerical_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# Create the correlation matrix\n",
    "correlation_matrix = df[numerical_cols].corr()\n",
    "\n",
    "# Find the two features with the strongest correlation\n",
    "max_corr = correlation_matrix.unstack().sort_values(ascending=False)\n",
    "# Ignore the diagonal (self-correlation)\n",
    "max_corr = max_corr[max_corr < 1].drop_duplicates()\n",
    "\n",
    "# Print the pair of features with the highest correlation\n",
    "print(max_corr.head(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target encoding\n",
    "\n",
    "Now we want to encode the y variable.\n",
    "\n",
    "Let's replace the values yes/no with 1/0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the 'y' column\n",
    "df['y'] = df['y'].map({'yes': 1, 'no': 0})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data\n",
    "\n",
    "Split your data in train/val/test sets with 60%/20%/20% distribution.\n",
    "\n",
    "Use Scikit-Learn for that (the train_test_split function) and set the seed to 42.\n",
    "\n",
    "Make sure that the target value y is not in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "df_train, df_temp = train_test_split(df, test_size=0.4, random_state=42)\n",
    "df_val, df_test = train_test_split(df_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Extract the target variable (y)\n",
    "y_train = df_train['y']\n",
    "y_val = df_val['y']\n",
    "y_test = df_test['y']\n",
    "\n",
    "# Remove the target variable from the features\n",
    "X_train = df_train.drop(columns=['y'])\n",
    "X_val = df_val.drop(columns=['y'])\n",
    "X_test = df_test.drop(columns=['y'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Calculate the mutual information score between y and other categorical variables in the dataset. Use the training set only.\n",
    "\n",
    "Round the scores to 2 decimals using round(score, 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                    0.01\n",
      "balance                0.02\n",
      "day                    0.01\n",
      "duration               0.07\n",
      "campaign               0.00\n",
      "pdays                  0.03\n",
      "previous               0.01\n",
      "job_admin.             0.00\n",
      "job_blue-collar        0.00\n",
      "job_entrepreneur       0.00\n",
      "job_housemaid          0.00\n",
      "job_management         0.00\n",
      "job_retired            0.00\n",
      "job_self-employed      0.00\n",
      "job_services           0.00\n",
      "job_student            0.00\n",
      "job_technician         0.00\n",
      "job_unemployed         0.00\n",
      "job_unknown            0.00\n",
      "marital_divorced       0.00\n",
      "marital_married        0.00\n",
      "marital_single         0.00\n",
      "education_primary      0.00\n",
      "education_secondary    0.00\n",
      "education_tertiary     0.01\n",
      "education_unknown      0.00\n",
      "housing_no             0.01\n",
      "housing_yes            0.02\n",
      "contact_cellular       0.01\n",
      "contact_telephone      0.00\n",
      "contact_unknown        0.01\n",
      "month_apr              0.00\n",
      "month_aug              0.00\n",
      "month_dec              0.00\n",
      "month_feb              0.00\n",
      "month_jan              0.00\n",
      "month_jul              0.00\n",
      "month_jun              0.00\n",
      "month_mar              0.01\n",
      "month_may              0.01\n",
      "month_nov              0.00\n",
      "month_oct              0.01\n",
      "month_sep              0.01\n",
      "poutcome_failure       0.00\n",
      "poutcome_other         0.00\n",
      "poutcome_success       0.03\n",
      "poutcome_unknown       0.02\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Select the categorical columns\n",
    "categorical_cols = ['job', 'marital', 'education', 'housing', 'contact', 'month', 'poutcome']\n",
    "\n",
    "# Apply One-Hot encoding on the categorical columns\n",
    "X_train_encoded = pd.get_dummies(X_train, columns=categorical_cols)\n",
    "\n",
    "# Calculate mutual information scores\n",
    "mi_scores = mutual_info_classif(X_train_encoded, y_train)\n",
    "\n",
    "# Display the results for the categorical variables\n",
    "mi_scores_df = pd.Series(mi_scores, index=X_train_encoded.columns).round(2)\n",
    "print(mi_scores_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variable with the highest mutual information score is 'duration' with a score of 0.07.\n"
     ]
    }
   ],
   "source": [
    "# Find the variable with the highest mutual information score\n",
    "max_mi_variable = mi_scores_df.idxmax()  # Get the index (variable name) with the highest score\n",
    "max_mi_score = mi_scores_df.max()         # Get the highest mutual information score\n",
    "\n",
    "# Print the result\n",
    "print(f\"The variable with the highest mutual information score is '{max_mi_variable}' with a score of {max_mi_score}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Now let's train a logistic regression.\n",
    "\n",
    "Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "\n",
    "Fit the model on the training dataset.\n",
    "\n",
    "To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "\n",
    "Calculate the accuracy on the validation dataset and round it to 2 decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# One-Hot encoding for all categorical variables\n",
    "X_train_encoded = pd.get_dummies(X_train)\n",
    "X_val_encoded = pd.get_dummies(X_val)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Calculate the accuracy on the validation set\n",
    "y_pred_val = model.predict(X_val_encoded)\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "print(\"Accuracy:\", round(accuracy_val, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "Let's find the least useful feature using the feature elimination technique.\n",
    "\n",
    "Train a model with all these features (using the same parameters as in Q4).\n",
    "\n",
    "Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "\n",
    "For each feature, calculate the difference between the original accuracy and the accuracy without the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with all features: 0.9005\n",
      "Feature 'marital' not found in the encoded features.\n",
      "Difference for age: -0.0002\n",
      "Difference for balance: -0.0003\n",
      "Difference for previous: -0.0001\n",
      "Feature with the smallest difference: balance\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Entraîner le modèle avec toutes les caractéristiques\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Précision avec toutes les caractéristiques\n",
    "accuracy_full = accuracy_score(y_val, model.predict(X_val_encoded))\n",
    "print(\"Accuracy with all features:\", round(accuracy_full, 4))\n",
    "\n",
    "# Liste des caractéristiques à évaluer\n",
    "features_to_evaluate = ['age', 'balance', 'marital', 'previous']\n",
    "\n",
    "# Dictionnaire pour stocker les différences\n",
    "differences = {}\n",
    "\n",
    "# Exclure chaque caractéristique et mesurer l'impact sur l'accuracy\n",
    "for feature in features_to_evaluate:\n",
    "    # Vérifier si la caractéristique est dans les colonnes\n",
    "    if feature in X_train_encoded.columns:\n",
    "        # Exclure la caractéristique\n",
    "        X_train_reduced = X_train_encoded.drop(columns=[feature])\n",
    "        X_val_reduced = X_val_encoded.drop(columns=[feature])\n",
    "        \n",
    "        # Entraîner le modèle sans cette caractéristique\n",
    "        model.fit(X_train_reduced, y_train)\n",
    "        \n",
    "        # Précision sans la caractéristique\n",
    "        accuracy_reduced = accuracy_score(y_val, model.predict(X_val_reduced))\n",
    "        \n",
    "        # Calculer la différence\n",
    "        difference = accuracy_full - accuracy_reduced\n",
    "        differences[feature] = round(difference, 4)\n",
    "    else:\n",
    "        print(f\"Feature '{feature}' not found in the encoded features.\")\n",
    "\n",
    "# Afficher les différences\n",
    "for feature, diff in differences.items():\n",
    "    print(f\"Difference for {feature}: {diff}\")\n",
    "\n",
    "# Trouver la caractéristique avec la plus petite différence\n",
    "if differences:  # S'assurer qu'il y a des différences à évaluer\n",
    "    least_impact_feature = min(differences, key=differences.get)\n",
    "    print(\"Feature with the smallest difference:\", least_impact_feature)\n",
    "else:\n",
    "    print(\"No valid features to evaluate.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Now let's train a regularized logistic regression.\n",
    "\n",
    "Let's try the following values of the parameter C: [0, 0.01, 0.1, 1, 10].\n",
    "\n",
    "Train models using all the features as in Q4.\n",
    "\n",
    "Calculate the accuracy on the validation dataset and round it to 3 decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.899\n",
      "Accuracy for C=0.1: 0.9\n",
      "Accuracy for C=1: 0.9\n",
      "Accuracy for C=10: 0.901\n",
      "Accuracy for C=100: 0.901\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Test different values of C, starting from a small positive value\n",
    "C_values = [0.01, 0.1, 1, 10, 100]  # Removed 0\n",
    "\n",
    "for C in C_values:\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "    \n",
    "    # Accuracy on the validation set\n",
    "    accuracy_val = accuracy_score(y_val, model.predict(X_val_encoded))\n",
    "    print(f\"Accuracy for C={C}: {round(accuracy_val, 3)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.899\n",
      "Accuracy for C=0.1: 0.9\n",
      "Accuracy for C=1: 0.9\n",
      "Accuracy for C=10: 0.901\n",
      "Accuracy for C=100: 0.901\n",
      "\n",
      "The best accuracy is 0.901 at C=10.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Test different values of C\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "best_accuracy = 0\n",
    "best_C = None\n",
    "\n",
    "# Loop through each C value\n",
    "for C in C_values:\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "    \n",
    "    # Calculate accuracy on the validation set\n",
    "    accuracy_val = accuracy_score(y_val, model.predict(X_val_encoded))\n",
    "    print(f\"Accuracy for C={C}: {round(accuracy_val, 3)}\")\n",
    "    \n",
    "    # Update the best accuracy and best C\n",
    "    if accuracy_val > best_accuracy:\n",
    "        best_accuracy = accuracy_val\n",
    "        best_C = C\n",
    "\n",
    "# Print the best accuracy and corresponding C\n",
    "print(f\"\\nThe best accuracy is {round(best_accuracy, 3)} at C={best_C}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
